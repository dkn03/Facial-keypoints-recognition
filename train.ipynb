{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import datetime\n",
    "\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import v2  \n",
    "from torch.utils.data import DataLoader\n",
    "from FaceDataset import FaceDataset\n",
    "\n",
    "\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../dataset/\"\n",
    "TRAIN_PATH = DATASET_PATH + \"/train/\"\n",
    "VALIDATION_PATH = DATASET_PATH + \"/validation/\"\n",
    "landmarks = json.load(open(DATASET_PATH + 'data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.Resize(256),\n",
    "    v2.CenterCrop(224),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_names: list[str], image_path: str, labels: dict[str: list], device=torch.device('cpu'), transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.image_names = image_names\n",
    "        self.image_path = image_path\n",
    "        self.labels = labels\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image = read_image(self.image_path + self.image_names[index]).to(dtype=torch.float)\n",
    "        label = self.labels[self.image_names[index]]\n",
    "        if not isinstance(label, torch.Tensor):\n",
    "            label = torch.tensor(label)\n",
    "        #label = label.to(device=self.device)\n",
    "        label = label.reshape(1, -1).squeeze()\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image / 255)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = os.listdir(TRAIN_PATH)\n",
    "validation_images = os.listdir(VALIDATION_PATH)\n",
    "\n",
    "train_dataset =  FaceDataset(train_images, TRAIN_PATH, landmarks, device, transforms=transforms)\n",
    "validation_dataset = FaceDataset(validation_images, VALIDATION_PATH, landmarks, device, transforms=transforms)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([136])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, scheduler, model, loss_fn, train_loader, validation_loader, ):\n",
    "    best_score = 0\n",
    "    best_epoch = 0\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for data, label in train_loader:\n",
    "            data = data.to(device=device)\n",
    "            label = label.to(device=device)\n",
    "            output = model(data)\n",
    "            #print(output.shape, label.shape)\n",
    "            loss = loss_fn(output, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        model.eval()\n",
    "        summary_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (data, label) in enumerate(validation_loader):\n",
    "                data = data.to(device=device)\n",
    "                label = label.to(device=device)\n",
    "                output = model(data)\n",
    "                \n",
    "                summary_loss += loss_fn(output, label)\n",
    "\n",
    "        validation_score = summary_loss/i\n",
    "\n",
    "\n",
    "        if best_score != 0 and best_score < validation_score:\n",
    "            counter += 1\n",
    "            if counter == 5:\n",
    "                print(f\"Early stop on epoch {epoch}\")\n",
    "                print(f\"Weights are loaded from epoch {best_epoch}\")\n",
    "                model.load_state_dict(best_weights)\n",
    "                break\n",
    "        else:\n",
    "            counter = 0\n",
    "            best_epoch = epoch\n",
    "            best_score = validation_score\n",
    "            best_weights = model.state_dict()\n",
    "\n",
    "        #if epoch == 1 or epoch % 5 == 0:\n",
    "\n",
    "        print('{} Epoch {}, Training loss {}, Validation loss {}, lr {}'.format(\n",
    "            datetime.datetime.now(),\n",
    "            epoch,\n",
    "            loss / len(train_loader),\n",
    "            validation_score,\n",
    "            scheduler.get_last_lr())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedResnet(torch.nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super().__init__()\n",
    "        self.model = resnet18(weights=weights)\n",
    "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, 68 * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        #return out.reshape(-1, 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-28 14:32:23.562110 Epoch 0, Training loss 0.020378483459353447, Validation loss 11.605183601379395, lr [0.001]\n",
      "2024-06-28 14:34:04.167827 Epoch 1, Training loss 0.03936924785375595, Validation loss 11.619023323059082, lr [0.001]\n",
      "2024-06-28 14:35:42.412578 Epoch 2, Training loss 0.01916358806192875, Validation loss 10.04627799987793, lr [0.001]\n",
      "2024-06-28 14:37:22.632751 Epoch 3, Training loss 0.01661578193306923, Validation loss 8.338556289672852, lr [0.001]\n",
      "2024-06-28 14:39:02.470662 Epoch 4, Training loss 0.014667359180748463, Validation loss 6.046509265899658, lr [0.001]\n",
      "2024-06-28 14:40:46.945296 Epoch 5, Training loss 0.019666526466608047, Validation loss 6.2515153884887695, lr [0.001]\n",
      "2024-06-28 14:42:30.681035 Epoch 6, Training loss 0.015752624720335007, Validation loss 5.361302375793457, lr [0.001]\n",
      "2024-06-28 14:44:08.948573 Epoch 7, Training loss 0.01403119321912527, Validation loss 4.727712154388428, lr [0.001]\n",
      "2024-06-28 14:45:43.202096 Epoch 8, Training loss 0.009277088567614555, Validation loss 3.9602339267730713, lr [0.001]\n",
      "2024-06-28 14:49:09.349839 Epoch 9, Training loss 0.013344752602279186, Validation loss 3.9499435424804688, lr [0.001]\n",
      "2024-06-28 14:51:34.528504 Epoch 10, Training loss 0.008272617124021053, Validation loss 3.8184170722961426, lr [0.001]\n",
      "2024-06-28 14:53:48.460869 Epoch 11, Training loss 0.008520843461155891, Validation loss 3.4901010990142822, lr [0.001]\n",
      "2024-06-28 14:55:42.216447 Epoch 12, Training loss 0.011737100780010223, Validation loss 4.036701679229736, lr [0.001]\n",
      "2024-06-28 14:57:25.400446 Epoch 13, Training loss 0.010127835907042027, Validation loss 3.630743980407715, lr [0.001]\n",
      "2024-06-28 14:59:50.345690 Epoch 14, Training loss 0.009784175083041191, Validation loss 3.411290407180786, lr [0.001]\n",
      "2024-06-28 15:01:34.310141 Epoch 15, Training loss 0.006516505964100361, Validation loss 3.5760626792907715, lr [0.001]\n",
      "2024-06-28 15:03:28.585437 Epoch 16, Training loss 0.012717640958726406, Validation loss 3.232215166091919, lr [0.001]\n",
      "2024-06-28 15:05:30.300000 Epoch 17, Training loss 0.006854701321572065, Validation loss 3.4982404708862305, lr [0.001]\n",
      "2024-06-28 15:07:46.015680 Epoch 18, Training loss 0.006030974444001913, Validation loss 2.9573817253112793, lr [0.001]\n",
      "2024-06-28 15:09:23.884557 Epoch 19, Training loss 0.006542843300849199, Validation loss 3.205477476119995, lr [0.0002]\n",
      "2024-06-28 15:11:05.299268 Epoch 20, Training loss 0.004528012592345476, Validation loss 2.7430453300476074, lr [0.0002]\n",
      "2024-06-28 15:12:43.926706 Epoch 21, Training loss 0.008300858549773693, Validation loss 2.7051844596862793, lr [0.0002]\n",
      "2024-06-28 15:14:23.767785 Epoch 22, Training loss 0.004332434386014938, Validation loss 2.696376085281372, lr [0.0002]\n",
      "2024-06-28 15:16:12.475643 Epoch 23, Training loss 0.005108882673084736, Validation loss 2.690322160720825, lr [0.0002]\n",
      "2024-06-28 15:18:18.135200 Epoch 24, Training loss 0.0051118554547429085, Validation loss 2.680382490158081, lr [0.0002]\n",
      "2024-06-28 15:21:08.343655 Epoch 25, Training loss 0.0032392742577940226, Validation loss 2.6462888717651367, lr [0.0002]\n",
      "2024-06-28 15:23:40.095229 Epoch 26, Training loss 0.0047277119010686874, Validation loss 2.633974552154541, lr [0.0002]\n",
      "2024-06-28 15:25:55.879762 Epoch 27, Training loss 0.005379807204008102, Validation loss 2.6056644916534424, lr [0.0002]\n",
      "2024-06-28 15:28:18.294848 Epoch 28, Training loss 0.005172122735530138, Validation loss 2.6189630031585693, lr [0.0002]\n",
      "2024-06-28 15:30:51.270150 Epoch 29, Training loss 0.00489481957629323, Validation loss 2.617457866668701, lr [0.0002]\n",
      "2024-06-28 15:33:54.250722 Epoch 30, Training loss 0.004557505249977112, Validation loss 2.592066526412964, lr [0.0002]\n",
      "2024-06-28 15:36:05.609429 Epoch 31, Training loss 0.004601635038852692, Validation loss 2.619572877883911, lr [0.0002]\n",
      "2024-06-28 15:37:57.351413 Epoch 32, Training loss 0.0033432492054998875, Validation loss 2.6142470836639404, lr [0.0002]\n",
      "2024-06-28 15:39:29.501373 Epoch 33, Training loss 0.0036532466765493155, Validation loss 2.6009297370910645, lr [0.0002]\n",
      "2024-06-28 15:41:01.945284 Epoch 34, Training loss 0.00495122279971838, Validation loss 2.5826518535614014, lr [0.0002]\n",
      "2024-06-28 15:42:34.325338 Epoch 35, Training loss 0.0046601672656834126, Validation loss 2.60286545753479, lr [0.0002]\n",
      "2024-06-28 15:44:08.341912 Epoch 36, Training loss 0.0036037589889019728, Validation loss 2.562281370162964, lr [0.0002]\n",
      "2024-06-28 15:45:41.104580 Epoch 37, Training loss 0.005198667291551828, Validation loss 2.563894033432007, lr [0.0002]\n",
      "2024-06-28 15:47:10.554980 Epoch 38, Training loss 0.0036640092730522156, Validation loss 2.5424766540527344, lr [0.0002]\n",
      "2024-06-28 15:48:39.566646 Epoch 39, Training loss 0.00303801242262125, Validation loss 2.550219774246216, lr [4e-05]\n",
      "2024-06-28 15:50:10.907125 Epoch 40, Training loss 0.010435705073177814, Validation loss 2.521796226501465, lr [4e-05]\n",
      "2024-06-28 15:51:45.291260 Epoch 41, Training loss 0.0038286170456558466, Validation loss 2.5192999839782715, lr [4e-05]\n",
      "2024-06-28 15:53:16.966686 Epoch 42, Training loss 0.003924159333109856, Validation loss 2.5087108612060547, lr [4e-05]\n",
      "2024-06-28 15:54:51.414736 Epoch 43, Training loss 0.004384783562272787, Validation loss 2.518954038619995, lr [4e-05]\n",
      "2024-06-28 15:56:23.825743 Epoch 44, Training loss 0.004929198883473873, Validation loss 2.5142405033111572, lr [4e-05]\n",
      "2024-06-28 15:57:55.976253 Epoch 45, Training loss 0.005475866142660379, Validation loss 2.51216721534729, lr [4e-05]\n",
      "2024-06-28 15:59:28.953568 Epoch 46, Training loss 0.005704889539629221, Validation loss 2.5051655769348145, lr [4e-05]\n",
      "2024-06-28 16:01:02.872480 Epoch 47, Training loss 0.0035712094977498055, Validation loss 2.5045058727264404, lr [4e-05]\n",
      "2024-06-28 16:02:32.990217 Epoch 48, Training loss 0.00316473632119596, Validation loss 2.507446527481079, lr [4e-05]\n",
      "2024-06-28 16:04:07.018305 Epoch 49, Training loss 0.004423616919666529, Validation loss 2.507641553878784, lr [4e-05]\n",
      "2024-06-28 16:05:42.942841 Epoch 50, Training loss 0.003789951093494892, Validation loss 2.5102219581604004, lr [4e-05]\n",
      "2024-06-28 16:07:22.389709 Epoch 51, Training loss 0.00314783095382154, Validation loss 2.504067897796631, lr [4e-05]\n",
      "2024-06-28 16:08:59.182364 Epoch 52, Training loss 0.004090119153261185, Validation loss 2.509671449661255, lr [4e-05]\n",
      "2024-06-28 16:10:38.180506 Epoch 53, Training loss 0.0038544482085853815, Validation loss 2.5102601051330566, lr [4e-05]\n",
      "2024-06-28 16:12:17.969597 Epoch 54, Training loss 0.0033822807017713785, Validation loss 2.4951817989349365, lr [4e-05]\n",
      "2024-06-28 16:13:59.337252 Epoch 55, Training loss 0.0025664858985692263, Validation loss 2.512176275253296, lr [4e-05]\n",
      "2024-06-28 16:15:35.253197 Epoch 56, Training loss 0.0034247594885528088, Validation loss 2.518167018890381, lr [4e-05]\n",
      "2024-06-28 16:17:20.828818 Epoch 57, Training loss 0.0038884454406797886, Validation loss 2.5030710697174072, lr [4e-05]\n",
      "2024-06-28 16:19:01.330341 Epoch 58, Training loss 0.004893644712865353, Validation loss 2.499333143234253, lr [4e-05]\n",
      "Early stop on epoch 59\n",
      "Weights are loaded from epoch 54\n"
     ]
    }
   ],
   "source": [
    "model = ModifiedResnet18().to(device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.SmoothL1Loss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=20, gamma=0.2)\n",
    "training_loop(n_epochs=200, optimizer=optimizer, model=model, loss_fn=loss_fn, scheduler=scheduler,\n",
    "              train_loader=train_dataloader, validation_loader=validation_dataloader)\n",
    "torch.save(model.state_dict(), \"resnet18_weights.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
